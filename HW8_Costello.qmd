---
title: "Homework 8: Basic Modeling Practice"
author: "Kim Costello"
format: html
editor: visual
---

### Seoul Bike Sharing Demand Dataset

```{r}
library(readr)
library(broom)
library(lubridate)
library(janitor)
library(dplyr)
library(ggplot2)
library(GGally)
library(tidymodels)
```

The following data set is provided by the UCI Machine Learning Repository. The data set contains count of public bicycles rented per hours in the Seoul Bike Sharing System, with corresponding weather data and holiday information.

The following variables are provided:

-   Date - day/month/year

-   Rented Bike count - Count of bikes rented at each hour

-   Hour - Hour of the day

-   Temperature-Temperature in Celsius

-   Humidity - %

-   Windspeed - m/s

-   Visibility - 10m

-   Dew point temperature - Celsius

-   Solar radiation - MJ/m2

-   Rainfall - mm

-   Snowfall - cm

-   Seasons - Winter, Spring, Summer, Autumn

-   Holiday - Holiday/No holiday

-   Functional Day - NoFunc(Non Functional Hours), Fun(Functional hours)

```{r}
# Read in data
bike_data <- read_csv("SeoulBikeData.csv", locale = locale(encoding = "latin1"))
```
#### EDA

```{r}
# check for missing values
colSums(is.na(bike_data))
```

The data provided does not contain any missing values.

```{r}
str(bike_data)
```

```{r}
summary(bike_data)
```

```{r}
unique(bike_data$Seasons)
unique(bike_data$Holiday)
unique(bike_data$`Functioning Day`)
```

```{r}
bike_data <- bike_data |>
  mutate(
     Date = dmy(Date),
     Seasons = as.factor(Seasons),
     Holiday = as.factor(Holiday),
     `Functioning Day` = as.factor(`Functioning Day`)
  ) |>
  clean_names("snake")
  
```

```{r}
# Two-way contingency tables
table(bike_data$functioning_day, bike_data$seasons)
table(bike_data$functioning_day, bike_data$holiday)
```

```{r}
bike_data |>
  group_by(functioning_day) |>
  summarize(across(where(is.numeric), 
                   list("mean" = mean, "median" = median), 
                   .names = "{.fn}_{.col}"))
```

```{r}
bike_data |>
  group_by(functioning_day) |>
  summarize(min_bike_count = min(rented_bike_count), max_bike_count = max(rented_bike_count))
  
```

No bikes were rented during non-functional hours.

```{r}
fun_bike_data <- bike_data |>
  filter(functioning_day == "Yes")
```

```{r}
bike_summary_data <- fun_bike_data |>
  group_by(date, seasons, holiday) |>
  summarize(
    sum_bike_count = sum(rented_bike_count),
    sum_rainfall = sum(rainfall_mm),
    sum_snowfall = sum(snowfall_cm),
    across(c(temperature_c, 
             humidity_percent,
             wind_speed_m_s,
             visibility_10m,
             dew_point_temperature_c,
             solar_radiation_mj_m2), 
           ~ mean(.x),
           .names = "mean_{.col}")
    
  )

head(bike_summary_data)

    
```

```{r}
table(bike_summary_data$seasons, bike_summary_data$holiday)
```

```{r}
bike_summary_data |>
  group_by(seasons) |>
  summarize(across(where(is.numeric), 
                   list("mean" = mean, "median" = median), 
                   .names = "{.fn}_{.col}"))
```

```{r}
bike_summary_data |>
  group_by(seasons) |>
  summarize(min_bike_count = min(sum_bike_count), max_bike_count = max(sum_bike_count))
```

```{r}
df_corr <- bike_summary_data |>
  select(where(is.numeric)) |>
  rename("Bike_count" = sum_bike_count,
         "Rainfall" = sum_rainfall,
         "Snowfall" = sum_snowfall,
         "Temperature" = mean_temperature_c,
         "Humidity" = mean_humidity_percent,
         "Windspeed" = mean_wind_speed_m_s,
         "Visibility" = mean_visibility_10m,
         "Dew_point" = mean_dew_point_temperature_c,
         "Solar_radiation" = mean_solar_radiation_mj_m2)

ggcorr(df_corr, 
       nbreaks = 6,
       label = TRUE,
       palette = "BuPu",
       size = 2,          # adjusting variable names sizes
       hjust = 0.65) +    # adjusting position of variable names) 
  labs(title = "Correlation Matrix of all Numeric Variables") +
  ggeasy::easy_center_title()
```

```{r}
df_corr |>
  group_by(seasons) |>
  summarize(correlation = cor(Bike_count, Temperature, use = "pairwise.complete.obs"))
```

```{r}
g <- ggplot(data = bike_summary_data)

g + geom_point(aes(x = sum_bike_count, 
                   y = sum_rainfall, 
                   color = seasons)) +
  labs(x = "Rental Bike Count", 
       y = "Rainfall (mm)",
       title = "Rental Bike Count by Total Daily Rainfall",
       color = "Seasons") +
  scale_color_manual(values = c("#FFFF00",
                                "#FF00FF",
                                "#7FFF00",
                                "#00FFFF")) +
  theme_dark() +
  ggeasy::easy_center_title() 
```

```{r}
g + geom_boxplot(aes(x = seasons, y = sum_bike_count, fill = holiday)) +
  labs(x = "Seasons", 
       y = "Daily Rental Bike Count",
       title = "Daily Rental Bike Count by Seasons",
       fill = "Holiday") +
  ggeasy::easy_center_title() +
  scale_fill_manual(values = c("lightpink",
                               "lightblue"))
```

```{r}
ggplot(bike_summary_data, aes(x = date, y = sum_bike_count)) +
  geom_point() +
  labs(x = "Date", 
       y = "Daily Rental Bike Count",
       title = "Daily Rental Bike Count by Date") +
  ggeasy::easy_center_title() +
  geom_smooth()
```

#### Splitting the Data

```{r}
# Fix the random numbers by setting the seed 
# This enables the analysis to be reproducible when random numbers are used 
set.seed(123)
# Put 3/4 of the data into the training set 
data_split <- initial_split(bike_summary_data, prop = 3/4, strata = seasons)

# Create data frames for the two sets:
train_data <- training(data_split)
test_data  <- testing(data_split)
```

```{r}
# Create cross validation folds on the training data
set.seed(234)
bike_folds <- vfold_cv(train_data, 10)
```

#### Fitting MLR Models

```{r}
recipe_one <- recipe(sum_bike_count ~ ., data = train_data) |> 
  update_role(date, new_role = "ID") |>
  step_date(date, features = "dow") |>
  step_mutate(day_of_week = 
                as.factor(ifelse(date_dow %in% c("Sat", "Sun"), "weekend", "weekday"))) |>
  step_rm(date_dow) |>     #removes intermediate variable
  step_normalize(all_numeric(), -all_outcomes()) |>
  step_dummy(seasons, holiday, day_of_week)

```

```{r}
recipe_two <- recipe(sum_bike_count ~ ., data = train_data) |> 
  update_role(date, new_role = "ID") |>
  step_date(date, features = "dow") |>
  step_mutate(day_of_week = 
                as.factor(ifelse(date_dow %in% c("Sat", "Sun"), "weekend", "weekday"))) |>
  step_rm(date_dow) |>     #removes intermediate variable
  step_normalize(all_numeric(), -all_outcomes()) |>
  step_dummy(seasons, holiday, day_of_week) |>
  step_interact(terms = ~starts_with("holiday")*starts_with("seasons") +
                  ~mean_temperature_c*starts_with("seasons") +
                  ~mean_temperature_c*sum_rainfall)
  

```

```{r}
recipe_three <- recipe(sum_bike_count ~ ., data = train_data) |> 
  update_role(date, new_role = "ID") |>
  step_date(date, features = "dow") |>
  step_mutate(day_of_week = 
                as.factor(ifelse(date_dow %in% c("Sat", "Sun"), "weekend", "weekday"))) |>
  step_rm(date_dow) |>     #removes intermediate variable
  step_normalize(all_numeric(), -all_outcomes()) |>
  step_dummy(seasons, holiday, day_of_week) |>
  step_interact(terms = ~starts_with("holiday")*starts_with("seasons") +
                  ~mean_temperature_c*starts_with("seasons") +
                  ~mean_temperature_c*sum_rainfall) |>
  step_poly(starts_with("mean"), sum_rainfall, sum_snowfall)
```


```{r}
bike_mod <- linear_reg() |>
  set_engine("lm")
```

```{r}
workflow_one <- workflow() |>
  add_recipe(recipe_one) |>
  add_model(bike_mod)

workflow_two <- workflow() |>
  add_recipe(recipe_two) |>
  add_model(bike_mod)

workflow_three <- workflow() |>
  add_recipe(recipe_three) |>
  add_model(bike_mod)

```

Fit the models using the 10 fold CV. 
```{r}
bike_CV_fit_one <- workflow_one |>
  fit_resamples(bike_folds)
bike_CV_fit_one

bike_CV_fit_one |>
  collect_metrics()
```

```{r}
bike_CV_fit_two <- workflow_two |>
  fit_resamples(bike_folds)
bike_CV_fit_two

bike_CV_fit_two |>
  collect_metrics()
```

```{r}
bike_CV_fit_three <- workflow_three |>
  fit_resamples(bike_folds)
bike_CV_fit_three

bike_CV_fit_three |>
  collect_metrics()
```

Model 3 is the best fit. 

```{r}
set.seed(123)
best_fit <- 
  workflow_three |>
  last_fit(data_split)

best_fit |>
  collect_metrics()
```

Make predictions on the test set and calculate RMSE. 
```{r}
test_fit <- extract_workflow(best_fit)
bike_predictions <- predict(test_fit, new_data = test_data) |>
  bind_cols(test_data |>
              select(sum_bike_count))   #add the true values

RMSE_test <- bike_predictions |>
  rmse(truth = sum_bike_count, estimate = .pred)
RMSE_test
```



```{r}
best_fit |>
  extract_fit_parsnip() |>
  tidy()
```

